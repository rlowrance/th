\chapter{Introduction}
% vim: textwidth=72

Many parties are interested in accurate predictions of the market
value of residential real estate. Buyers and sellers have a clear
interest in setting prices relative to market values. Mortgage
originators, who use the property as collateral for the loan, want to
know the extent to which the borrower starts with and continues to have
equity in the house.  Investors in mortgages want to know the current
value of the property relative to the current debt on the property.
Local governments use market values in part to set real estate
taxes.

With so much interest, it is not surprising that a business has arisen
in predicting market values of residences. The structure of this
market comprises a few large national players and many regional
players. The players regard their algorithms and often their data
as sources of competitive advantage.

Academic studies of real estate pricing models have been limited by data
availability and the absence of benchmarks from the commercial players.
Most academic studies are generated around a data set for one city for
one year. Often the data are licensed only to specific scientists.


This work systematically compares linear models for predicting prices of
single-family residential real estate in Los Angles County over a time
period that precedes and follows the real estate crash. The data are
from CoreLogic, one of the providers of both the data and algorithms
for real estate price prediction. As for other academic work, the data
are proprietary to the study. However, the source code for the work is
licensed under the GPL and is available on the author's Github account.
It is written in R and its models are designed to work on any data set.

We develop a few insights into linear models of real estate prices. All
these findings are for Los Angeles County residential real estate
transactions between 2003 and the first part of 2009.

\begin{itemize}

\item A lot of data doesn't help a lot. Linear models price houses by
pricing each feature of the house. When
house values are changing, the hedonic nature of the linear model must
mean that feature values are also changing. While training a model on a
longer time period will smooth noise, it will also use older
feature prices that are not necessarily relevant to feature prices at
the time of the query. We find an optimal time period is roughly 60 days,
considering both time periods before and after the real estate crash.

\item One might suppose that a very valuable feature would be the value
of the house as estimated by the real estate tax assessor. However, we
found that during the crash, the value of the tax assessment was
negative when used in simple linear models.

\item ``Location, location, location'' are said by some real estate
agents to be the most important feature of a house. We find that isn't
true, at least for linear models. The most important feature of the
house is its interior living space. The second most important feature
of the house is a feature related to location: the median income of the
census tract holding the house.

%\item The most valuable single feature in determining price is not the
%size of the lot, as one might suspect. Instead, the most valuable single
%feature is the interior living space. This explains in part a trend
%toward knocking down houses and building bigger houses: value is
%increased.

% Data from figure 3 in chapter 5
% n features   median RMSE
%          5   69467      120
%         20   57880      100

\item One would hope that a few features of houses would contain most of
the information that is driving prices. If so, models could be simpler.
We find, however, that the most accurate linear model contains 20
features. An otherwise identical model that uses only the 5 most
features has an estimated error that is 20 percent higher. Using more
features means more opportunities for overfitting, and we find that
regularization improved predictive accuracy.

%\item Linear models price houses by estimating the value of features.
%It's not surprising that some features are worth more in some
%neighborhoods than in others. By partitioning all the houses into
%suitably-defined neighborhoods (called submarkets in the literature),
%prediction accuracy can be improved.

\item Linear models are popular in part because they are relatively easy
to understand and quick to fit. However, they tend to underperform
non-linear models. We demonstrate that random forests greatly outperform
linear models and have the additional advantage of requiring almost no
design decisions.

\end{itemize}

The remaining chapters are these. Chapter 2 contains a review of the
literature, focusing on other studies of real estate price prediction
models. Chapter 3 describes how the Los Angeles data were ingested,
cleaned up, and converted into transactions. We end up with about 1.2
million transactions mostly dated from 1984 through the early part of
2009.  Chapter 4 describes our work to find a subset of the Los Angeles
data that is both informative for prediction purposes and does not
contain any future information.  Chapter 5 identifies the best linear
models, at least according to our experiments on these data. It also
describes a random forests model with superior performance to the best
of the linear models. Chapter 6 presents overall conclusions that lead
to future work I'd like to do.

%\layout    % see Gratzer p 268

