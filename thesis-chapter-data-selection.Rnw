\chapter{Data Selection}
% vim: textwidth=72
% vim: foldmethod=manual

<<DataSelection>>=
working <- control$working
path.cv.assessment.vertical <- paste0(working, 'e-cv-chart_chart5_vertical.txt')
path.cv.census.vertical <- paste0(working, 'e-cv-chart_chart6_vertical100.txt')
path.verify <- paste0(working,'e-verify-assessment-chart_chart1.pdf')
path.price.chart2 <- paste0(working, 'e-price-chart_chart2.pdf')
@

We'd like to investigate a range of real estate price prediction
models over as many years as possible. Most academic studies of real
estate prices cover just one year of transactions. Unfortunately, the
overlap in time periods for our data sets is small.
\begin{itemize}

\item The deeds files contained deeds for 1984 through the first part of
2009. A few deeds from years before 1984 were thrown in.

\item The tax roll file was for 2008. It was created in late 2007. It
contains property descriptions as well as the tax assessor's estimated
value for the house. It also contained the census tract number for each
house.

\item The census file contained data from the decennial census in
year 2000. It became available to the public sometime in 2002.

\end{itemize}

Thus, the common time period was starting in 2008 and extended into a
few months in 2009.

This time period could have been extended to earlier time periods if we
could have concluded that the tax assessment did not carry much
predictive value.  If that were so, we could have simply not used features
derived from the tax assessment and extended the analysis back to 2003,
when the year 2000 census data became available.

Furthermore, we could have extended the time period back before 2003, if the
census data were also not valuable for predictive purposes.

To determine whether feature sets were valuable for predictive purposes,
we employed a cross validation and model-testing process using the training data.

The remainder of this chapter is sectionalized.

\begin{itemize}

\item Section 1 describes the cross-validation process and how models
were fitted and used for prediction.

\item Section 2 provides an overview of real estate taxes in
California.

\item Section 3 answers the question: Are the tax assessment-derived
features valuable for predicting prices?

\item Section 4 provides an overview of the U.S. decennial census and
the year 2000 census in particular.

\item Section 5 answers the questions: Are the census-derived features
valuable for predicting prices?

\item Section 6 provides a brief summary of the findings: the tax
assessment-derived features were not valuable and the census-tract
derived features were valuable.

\end{itemize}

\section{Cross Validation and Model Fitting}

We compared a large number of models with the goal of selecting
the models that are best for predictive purposes. In this work, ``best''
means that the model provided the lowest estimated generalization error,
which was defined to be the estimated error on data that the trained
model had never seen.

To estimate the generalization error, we used 10-fold cross validation,
as described in \cite[Chapter 7, starting p.~214]{hastie-01}. Our
implementation of cross validation assigned each of the training samples
randomly to one of 10 folds and then trained 10 sets of models. We used
the standard 10-fold cross validation approach: for each fold, we
defined training folds containing 90 percent of the data and a testing
fold containing 10 percent of the data.

For each of the samples in the testing fold, we built a local model
just for that sample, which we called the query transaction. To avoid
using the future in the training process, we first discarded all data in
the training folds that occured on or after the date of the query
transaction. A model was then trained on the remaining data in the
training folds. The trained model was then used to predict the query
transaction's price and the results were recorded.

There were many local models to be fit. Just before the models were
fitted, the feature set was analyzed to detect and eliminate any
feature that would not meet the requirements of the underlying model.
For example, usually the model required that no feature had the same
value for every transaction.  We made this tradeoff: we kept the
transaction in the fold's test set using fewer features than are
specified in the model rather than discarding the test transactions. In
a fold, usually very test transactions have discarded features.

One optimization speed up the fitting process. All models with the same
query date were fitted to the same training data because the training
process did not use the query transaction or any data on or after the
date of the query transaction. Thus the same fitted model could be used
for every query transaction on a given date.

\section{Understanding the Real Estate Tax Assessment}

% including a pdf
\begin{figure}[h]
\caption{
Fraction of Property Sales For Exactly Their 2008 Assessments \\
By Recording Year and Month\\
For 2006 Through 2009
}
\label{figure:AssessmentExactlyEqual}
\centering\includegraphics[scale=.4]{\Sexpr{path.verify}}
\end{figure}

In the United States, local government is often financed in part through
real estate taxes \cite{wiki-14-property-tax}. The taxing authority,
often a county, creates a tax assessor which values the land and the
improvements on the land. The resulting assessed values are used to
determine the assessment, the amount of taxes due. For example, the
assessment may be calculated as a fraction of the total assessed value
of the land and its improvements.  The assessed value may be the market
value or a stated fraction of the market value or, as in California,
have some other relationship to market value. How often the
assessments are carried out depends on the local government.

The tax assessment is possibly a useful feature to know when creating
real estate valuation models. Figure \ref{figure:AssessmentExactlyEqual}
depicts the fraction of residential properties recorded in certain
months in Los Angles County relative to what is called the 2008 tax
assessment.  We see that in the period July, 2007 through December,
2007, many of the properties, about 90 percent, sold for exactly their
assessed values. This did not happen in other periods. What is going on?

The answer lies in California Proposition 13.

%The answers lies in the nature of the property tax system in Los Angeles
%County. According to the website of the Los Angeles County Office of
%the Assessor \cite{lac-14-real-property-assessments}, the Assessor
%determines the assessed value for property, the Auditor-Controller
%applies the appropriate tax rate for the property, and the Treasurer \&
%Tax Collector mails out the bills and collects the money.

California Proposition 13 \cite{californiataxdata-14-prop13}, passed in
1978, changed the relationship between market values and assessed
values. Assessments were reset to their 1976 levels.  Increases from the
1976 level were limited to two percent per year, unless the property
sold (with a few exceptions). Properties that sold were assessed at
their selling prices.

%Our foscus is on the assessed value. In
%this section, we further focus on the total assessed value, the sum of
%the assessed values for the land and any improvements (buildings and
%structures) on the land. California law defines the assessed value using
%the market value as a starting point. Several major cases are recognized (minor cases
%are not documented here):
%\begin{itemize}
%\item The property sold or was inherited. The assessed value becomes the
%market value. There are exceptions for transfers between husband and
%wife and domestic partners and a few other situations. The date for the
%adjustment is the recording date, not the sale date.
%\item New construction was completed on the property. The improvement
%value is increased to reflect the value of the new construction. The
%value of the improvement comes from construction permits.
%\item The property neither sold nor had completed new construction. This
%is the most interesting case. The previous assessed value is adjusted to
%reflect movement in market values, however the adjustment is never more
%than two percent per annum, no matter the rate of inflation.
%\end{itemize}


The net effect is that the assessor's assessed value is below the
market value in periods with inflation of more than two percent for
homes that did not sell in the previous year.

%In addition, California Proposition 8, also passed in 1978
%\cite{caboe-14-prop8} provides for a temporary reduction in assessed
%values when the value of a property falls. The effect is to reinforce
%that assessed values can be below market values.

One final note on timing. The tax bills are mailed between October 1 and
October 31 \cite{lac-14-important-dates-for-homeowners} with initial
payment due on November 1. The fiscal year for Los Angeles County
begins July 1.

Now we have the background to hypothesize an explanation for the many
zero-error points in the second half of 2007 in Figure
\ref{figure:AssessmentExactlyEqual}. The assessor set the assessment
for 2008 equal to the transaction prices for properties transacted in
2007 starting in July, when the fiscal year began. Assessed values for
properties transacting before July 2007 were set in some other manner.
The figure reflects recording dates, which tend to lag sales dates by a
few months.  Thus the properties reported as transacting in November and
December in many cases would have transacted a few months early, say
ending in roughly October. The last day for publishing tax assessments
is October 31.

\section{Testing the Predictive Value of the Assessment}

We turn now to a key question: to what extent is the assessed value
useful in predicting real estate prices when using linear models?

To answer this question, we compared two linear models that are otherwise
identical except for the feature sets used. One model used the tax data,
one did not. In order to determine which of the two models was better, we
estimated the generalization error from each model using 10-fold cross
validation.

The common feature set across each model contained all the features that
were present in every transaction of subset 1. The features were
structured into six groups along two axis. The first axis is the source
of the feature: from the tax bills, from the U.S.
Census Bureau, or from the deeds file. The second axis is whether the
feature describes the size of the property: yes or no.

% ref: Predictors2.R
These two axis resulted in six feature sets.
\begin{itemize}

\item From the tax bills presented in late 2007.
  \begin{itemize}
  \item Size features: improvement value, land value.
  \item Non-size features: fraction improvement value (ratio of the
  improvement value to the sum of the improvement and land values).
  \end{itemize}

\item From the U.S. Census Bureau decennial census in year 2000.
  \begin{itemize}
  \item Size features: there are no such features.
  \item Non-size features: average commute time; fraction of houses that
  were owned by the occupants; median household income; whether the census
  tract had a park, retail stores, a school, and industry.
  \end{itemize}

\item From the deeds files for the years 1984 through 2009.
  \begin{itemize}
  \item Size features: land square footage, living area,
  basement square feet, number of bathrooms, number of bedrooms, number
  of fireplaces, number of parking spaces, number of stories, and number
  of rooms.
  \item Non-size features: effective year built; year built; whether
  there was a pool; whether the house was newly constructed; whether the
  five-digit zip code had a park, retail stores, a school, and industry.
  When constructing the models, the year and effective year built
  features were converted to age, age squared, effective age, and
  effective age squared using the sale date from the query transaction.
  This conversion was made because age and age squared are popular
  features in the literature. The idea is that houses may depreciate
  for a while and then gain in value as they become classics.
  \end{itemize}

\end{itemize}

In addition to varying the feature set, we varied other design choices
in linear models:
\begin{itemize}

\item Response variable. One can choose to predict the price of the
house or the logarithm of the price.

\item Prediction variable forms. One can choose to predict using the
natural units for the predictor features or by transforming the size
features into the log domain.

\item Number of days of training data. Prices were moving rapidly
downward in 2007. With linear models, using a longer period for the
training data runs the risk of irrelevance of the training data to the
query date. If prices were stable, a longer training period could
provide a more accurate estimated price.

\end{itemize}


\begin{figure}[ht]
%\tiny
\scriptsize
%\footnotesize
%\small
%\normalsize
\verbatiminput{\Sexpr{path.cv.assessment.vertical}}
\caption{
Estimated Generalization Errors\\ 
With and Without the Assessed Value\\
By Response Variable, Predictors, and Training Period\\
For Sales in 2008
}
\label{figure:CvAssessmentVertical}
\end{figure}

Figure \ref{figure:CvAssessmentVertical} contains the results from the
cross validation study. Column one states the number of days in the
training period. Each cell after column one contains the median of the
RMSE values from 10-fold cross validation. Here RMSE means the square
root of the median squared errors. Thus each cell contains an estimate
of the generalization error.

Column two contains estimated errors for the level-level form of the
model, which estimates price, and features that use the tax assessment.
Column three is also for the level-level form of the model, but does not
use the tax assessment. 

Comparing columns two and three, we see that in every case the estimated
errors are lower if we do not use the tax assessment-derived features.
This is true for every column pair. Using the tax assessment always
led to higher estimated errors.


\begin{figure}[h]
\caption{
Median Price\\
By Month \\
For 2006 - 2009
}
\label{figure:PricesByMonth2006On}
\centering\includegraphics[scale=.4]{\Sexpr{path.price.chart2}}
\end{figure}

The key conclusion from the figure is that using the 2008 tax assessment
as a feature never reduced the estimated generalization error. Examining
Figure \ref{figure:PricesByMonth2006On} shows why: median prices in 2008
fell every month, so that the assessed values became increasingly
obsolete.

Thus we reached an unexpected conclusion: the assessed values were not
necessarily useful in linear models. One reason is that in California,
Proposition 13 biases the assessed values to be less than market values
on some properties but not others. Another reason is that the
assessment may become obsolete if market values are either increasing or
decreasing rapidly.

\section{Understanding the Census Data}

The United States Census Bureau conducts
\cite{census-bureau-14-website} a decennial census every 10 years. The
year 2000 census \cite[p.~140]{census-bureau-12-measuring} began in
March 2000 to survey all 98 million households. The survey technique was
to mail surveys and follow up with non-respondents by sending
``enumerators'' to the household. 

Two survey forms were used in 2000.
\begin{itemize}
\item Short-form: Most households (83 percent) received a questionnaire
asking for information on ``name, sex, age, relationship, Hispanic origin,
and race.''
\item Long-form: Some households (17 percent) received a questionnaire
that asked for both the short-form information and an additional ``52
questions requesting \dots information about housing, social, and
economic characteristics of the household.''
\end{itemize}

Data were captured for each household and then aggregated for reporting
purposes. The lowest level of aggregation was the census block. Data from
census blocks were further aggregated into several hierarchies
\cite{census-bureau-10-geodiagram}. The hierarchy of interest to this
work had these levels: nation, region, divisions, states, counties,
census tracts, block groups, and census blocks. All of the census data
we used were from the 2000 census for Los Angeles County and were at the
census tract level.

Boundaries between census tracts in Los Angeles changed between the 2000
and 2010 censuses \cite{proximityone-14-tracts}.  That's because
census tracts are designed to contain about 4,000 people: as populations
grow and shrink, census tracts need to be redefined.  Indeed, an
analysis of Los Angeles County census data at the census tract level
for years 1990 and 2000 shows an increase in the number of census tracts
in Los Angeles County, consistent with an increase in the Los Angeles
County population.

Unfortunately, the census tract numbers we used for properties were
contained in the tax roll, which we had only for 2008. Thus we could not
easily determine census tract numbers for parcels for the 1980 nor 1990
censuses. The implication was that the earliest date we could use the
census data we had was for the date when it first became available.
According to the help line for the Census Bureau, the year 2000 census
data became public sometime in 2002.  Rather than determine that date
exactly, we assumed that transactions on or after January 1, 2003
properly reflect census data from the year 2000 census.

\section{Assessing the Predictive Power of the Census Data}

To assess whether features derived from the year 2000 census were
valuable, we used 10-fold cross validation to estimate the
generalization error for a variety of linear models, all trained and
tested on data from 2003 on. The models varied the same design choices
as for the experiments to understand the predictive power of features
derived from the 2008 tax assessment. These choices were:

\begin{itemize}
\item response variable: predict either the price or the logarithm of
the price.
\item prediction variable forms: use as predictors both the natural
units of the predictors (called ``level'' in the chart) or the logarithm
of the natural units.
\item number of training days: vary the training period from 30 days to
360 in steps of 30 days.
\end{itemize}

\begin{figure}[ht]
%\tiny
\scriptsize
%\small
%\normalsize
\verbatiminput{\Sexpr{path.cv.census.vertical}}
\caption{
Estimated Generalization Errors\\
With and Without Census Data
By Response Variable, Predictors, and Training Period
}
\label{figure:EGECensusVertical}
\end{figure}

Figure \ref{figure:EGECensusVertical} shows the estimated generalization error
for each of the design choices, both with and without the features
derived from the census data. The comparison metric is the median of the
root median squared errors from the folds. The key finding was that
using the census-derived features always led to better performance.


\section{Discarding Assessments and Keeping Census Data}

Because the assessment data were not valuable for the time period for
which they were relevant, namely the year 2008, we decided to discard all
features derived from the assessment. This decision reduced our
available feature set and allowed us to use transactions before and after
2008.

Because the census data were valuable for the time period in which they
were relevant, namely beginning in 2003, we decided to keep these
features and restrict the analysis to year 2003 and later. The resulting
dataset had about 250,000 transactions. The median price over the time
period was \$475,000.
