\chapter{Conclusions and Future Work}
% vim: textwidth=72

We have systematically designed a local linear model with the goal of
finding a model that has the lowest expected error on unseen data. The
best model we found was tailored to zip codes using indicator variables,
trained on 30 days of data prior to the query transaction, predicted the
log of the price, was regularized, and used 15 features in their natural
units. 

The random forests models we tested performed better than the
local linear model we designed.

These ideas for future work seem potentially fruitful:

\begin{itemize}

\item Understand better why submarket models had higher errors for more
expensive properties. Was it because they trade based on features we
don't see? If so, can one obtain data on these features? If not, can the
latent features be none-the-less learned?

\item Compare local linear models to other non-linear models found in the
literature to outperform linear models. Two to consider are neural
networks and the ``Additive Regression'' from
\cite{zurada-11-comparison}.

\item Consider enhanced feature sets. Include the GPS coordinates as
features. Compare direct usage of GPS coordinates to the trend surface
$x,y$ feature sets (as studied in \cite{fik-03-spatial}).

\item Evaluate using deep learning techniques to generate feature sets.
Most of the deep learning research is in domains where the best feature
set is far from obvious. A research issue is: Can deep learning find
feature sets that outperform feature sets found in the real estate
pricing literature?

\end{itemize}

Some other ideas would help encourage others to work in the field of
real estate price prediction. The most important is to arrange for a
multiyear contemporary data set to be put in the public domain. Another
idea is to develop an open source package that allowed real estate
pricing models to be compared. The present work, which open sources its
code, provides a start on such a package.
